import os
import subprocess
import time
import uuid
import json
from collections.abc import Iterable
from pathlib import Path
from urllib.parse import urlparse, urlunparse
from urllib.request import urlopen
from fastapi import FastAPI, HTTPException
from openhands.sdk.conversation.conversation import Conversation
from pydantic import SecretStr

from openhands.sdk import LLM, get_logger
from openhands.sdk.conversation.impl.remote_conversation import RemoteConversation
from openhands.sdk.preset.default import get_default_agent
from openhands.sdk.sandbox import DockerSandboxedAgentServer
from openhands.sdk.sandbox.docker import _run, find_available_tcp_port, build_agent_server_image


"""
ç¤ºä¾‹ 24ï¼šåœ¨æ²™ç®±åŒ–çš„ Agent Server ä¸­è¿è¡Œ GitLab é›†æˆï¼ˆæ”¯æŒä¼šè¯çŠ¶æ€æŒä¹…åŒ–ï¼‰

æœ¬ä¾‹æ¼”ç¤ºå¦‚ä½•ï¼š
  1) æ„å»ºå¹¶å¯åŠ¨ OpenHands Agent Server çš„ DEVï¼ˆæºç ï¼‰Docker é•œåƒ
  2) åˆ›å»ºä¸€ä¸ª FastAPI åº”ç”¨ç¨‹åºæ¥å¤„ç† GitLab ç›¸å…³æ“ä½œ
  3) ä¸æ²™ç®±åŒ–çš„æœåŠ¡å™¨äº¤äº’ä»¥æ‰§è¡Œ GitLab ä»»åŠ¡
  4) å°†ä¼šè¯çŠ¶æ€æŒä¹…åŒ–åˆ°å®¿ä¸»æœºæ–‡ä»¶ç³»ç»Ÿï¼Œå³ä½¿é‡æ–°åˆ›å»ºå®¹å™¨ä¹Ÿèƒ½ä¿ç•™å¯¹è¯çŠ¶æ€

æ³¨æ„ï¼šè¿™æ˜¯æ‰©å±•ç‰ˆæœ¬ï¼Œé€šè¿‡ç»§æ‰¿ DockerSandboxedAgentServer å®ç°æŒä¹…åŒ–ï¼Œ
è€Œä¸éœ€è¦ä¿®æ”¹ SDK æ ¸å¿ƒä»£ç ã€‚
"""

logger = get_logger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="GitLab Integration Server",
    description="A server for handling GitLab operations with OpenHands agents (with persistence)",
    version="0.1.0"
)


class PersistentDockerSandboxedAgentServer(DockerSandboxedAgentServer):
    """
    æ‰©å±• DockerSandboxedAgentServer ä»¥æ”¯æŒæŒä¹…åŒ–ç›®å½•æŒ‚è½½
    """

    def __init__(
        self,
        *,
        base_image: str,
        host_port: int | None = None,
        host: str = "127.0.0.1",
        forward_env: Iterable[str] | None = None,
        mount_dir: str | None = None,
        detach_logs: bool = True,
        target: str = "source",
        platform: str = "linux/amd64",
        persistent_dirs: dict[str, str] | None = None,  # æ–°å¢ï¼šæŒä¹…åŒ–ç›®å½•æ˜ å°„
    ) -> None:
        super().__init__(
            base_image=base_image,
            host_port=host_port,
            host=host,
            forward_env=forward_env,
            mount_dir=mount_dir,
            detach_logs=detach_logs,
            target=target,
            platform=platform,
        )
        # æŒä¹…åŒ–ç›®å½•æ˜ å°„ï¼šå®¹å™¨è·¯å¾„ -> å®¿ä¸»æœºè·¯å¾„
        self.persistent_dirs = persistent_dirs or {}

    def __enter__(self) -> 'PersistentDockerSandboxedAgentServer':
        # ç¡®ä¿ docker å­˜åœ¨
        docker_ver = _run(["docker", "version"]).returncode
        if docker_ver != 0:
            raise RuntimeError(
                "Docker is not available. Please install and start "
                "Docker Desktop/daemon."
            )

        # æ„å»ºé•œåƒï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self._image and "ghcr.io/all-hands-ai/agent-server" not in self._image:
            self._image = build_agent_server_image(
                base_image=self._image,
                target=self._target,
                # æˆ‘ä»¬åªæ”¯æŒå•å¹³å°
                platforms=self._platform,
            )

        # å‡†å¤‡ç¯å¢ƒæ ‡å¿—
        flags: list[str] = []
        for key in self._forward_env:
            if key in os.environ:
                flags += ["-e", f"{key}={os.environ[key]}"]

        # å‡†å¤‡æŒ‚è½½æ ‡å¿— - åŒ…æ‹¬å·¥ä½œç›®å½•å’ŒæŒä¹…åŒ–ç›®å½•
        if self.mount_dir:
            mount_path = "/workspace"
            flags += ["-v", f"{self.mount_dir}:{mount_path}"]
            logger.info(
                "æŒ‚è½½å®¿ä¸»æœºç›®å½• %s åˆ°å®¹å™¨è·¯å¾„ %s", self.mount_dir, mount_path
            )

        # æ·»åŠ æŒä¹…åŒ–ç›®å½•æŒ‚è½½
        for container_path, host_path in self.persistent_dirs.items():
            os.makedirs(host_path, exist_ok=True)  # ç¡®ä¿å®¿ä¸»æœºç›®å½•å­˜åœ¨
            flags += ["-v", f"{host_path}:{container_path}"]
            logger.info(
                "æŒä¹…åŒ–æŒ‚è½½å®¿ä¸»æœºç›®å½• %s åˆ°å®¹å™¨è·¯å¾„ %s", host_path, container_path
            )

        # è¿è¡Œå®¹å™¨
        run_cmd = [
            "docker",
            "run",
            "--user", "0:0",
            "-d",
            "--platform",
            self._platform,
            # "--rm",  # æ³¨æ„ï¼šæˆ‘ä»¬ä»ç„¶ä½¿ç”¨ --rmï¼Œä½†æ•°æ®é€šè¿‡æŒ‚è½½å·æŒä¹…åŒ–
            "--name",
            f"agent-server-{int(time.time())}",
            "-p",
            f"{self.host_port}:8000",
            *flags,
            self._image,
            "--host",
            "0.0.0.0",
            "--port",
            "8000",
        ]
        proc = _run(run_cmd)
        if proc.returncode != 0:
            raise RuntimeError(
                f"Failed to run docker container: {proc.stderr}")

        self.container_id = proc.stdout.strip()
        logger.info("Started container: %s", self.container_id)

        # å¯é€‰åœ°åœ¨åå°æµå¼ä¼ è¾“æ—¥å¿—
        if self.detach_logs:
            from threading import Thread, Event
            self._logs_thread = Thread(
                target=self._stream_docker_logs, daemon=True
            )
            self._logs_thread.start()

        # ç­‰å¾…å¥åº·æ£€æŸ¥
        self._wait_for_health()
        logger.info("API server is ready at %s", self.base_url)
        return self


@app.get("/createConversation")
async def create_conversation(message: str, git_repos: list[str], git_token: str) -> str:
    """åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è¯"""
    # 1)åˆ›å»ºä¼šè¯å¯¹åº”çš„å·¥ä½œç›®å½•
    base_dir = os.environ.get(
        "HOST_WORKSPACE_DIR",
        os.path.abspath(os.path.join(os.path.dirname(__file__), "..")),
    )
    host_workspace = os.path.abspath(base_dir)
    workspace_id = uuid.uuid4()
    host_working_dir = os.path.join(
        host_workspace, "workspace", str(workspace_id))
    os.makedirs(host_working_dir, exist_ok=True)
    
    # ä¿å­˜å¯¹è¯IDåˆ°å·¥ä½œç›®å½•çš„æ˜ å°„
    conversation_mapping_file = os.path.join(host_workspace, "conversation_mapping.json")
    conversation_id_str = None
    token = (git_token or "").strip()
    for idx, repo_url in enumerate(git_repos):
        repo_url = repo_url.strip()
        if not repo_url:
            continue
        repo_name = repo_url.rstrip("/").split("/")[-1] or f"repo_{idx}"
        if repo_name.endswith(".git"):
            repo_name = repo_name[:-4]
        dest_path = os.path.join(host_working_dir, repo_name)
        if os.path.exists(dest_path):
            logger.info(f"ä»“åº“å·²å­˜åœ¨ï¼Œè·³è¿‡å…‹éš†ï¼š{repo_url}")
            continue
        clone_url = repo_url
        if token and token.lower() != "none":
            parsed = urlparse(repo_url)
            if parsed.scheme in {"http", "https"} and not parsed.username and parsed.hostname:
                port = f":{parsed.port}" if parsed.port else ""
                netloc = f"oauth2:{token}@{parsed.hostname}{port}"
                clone_url = urlunparse(parsed._replace(netloc=netloc))
        try:
            subprocess.run(
                ["git", "clone", "--depth", "1", clone_url, dest_path],
                check=True,
                cwd=host_working_dir,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
        except subprocess.CalledProcessError as exc:
            detail = exc.stderr or str(exc)
            if token:
                detail = detail.replace(token, "***")
                detail = detail.replace(f"oauth2:{token}", "oauth2:***")
            raise HTTPException(
                status_code=400,
                detail=f"å…‹éš†ä»“åº“å¤±è´¥: {repo_url}\n{detail}",
            ) from exc

    # 1) ç¡®ä¿æˆ‘ä»¬æ‹¥æœ‰ LLM API Key
    api_key = os.getenv("LITELLM_API_KEY")
    assert api_key is not None, "æœªè®¾ç½® LITELLM_API_KEY ç¯å¢ƒå˜é‡ã€‚"

    llm = LLM(
        service_id="main-llm",
        model="openai/Qwen3-Next-80B-A3B-Instruct-FP8",
        base_url="https://oneapi.wchat.cc/v1",
        api_key=SecretStr(api_key),
    )

    # 2) ä¸ºæŒä¹…åŒ–åˆ›å»ºå®¿ä¸»æœºç›®å½•
    host_workspace = os.path.abspath(base_dir)
    host_agent_workspace = os.path.join(
        host_workspace, ".conversations")
    os.makedirs(host_agent_workspace, exist_ok=True)

    # 3) ä½¿ç”¨ç›¸åŒçš„æŒä¹…åŒ–ç›®å½•å¯åŠ¨å®¹å™¨
    with PersistentDockerSandboxedAgentServer(
        base_image="ghcr.io/all-hands-ai/agent-server:4864c6f-custom-dev",
        mount_dir=host_working_dir,
        persistent_dirs={
            "/agent-server/workspace/conversations": host_agent_workspace,       # æŒä¹…åŒ–Agentå·¥ä½œåŒºæ•°æ®
        },
    ) as server:
        # 4) åˆ›å»º Agent â€”â€” å…³é”®ï¼šworking_dir å¿…é¡»æ˜¯å®¹å™¨å†…æŒ‚è½½ä»“åº“çš„ä½ç½®
        agent = get_default_agent(
            llm=llm,
            working_dir="/workspace",
            cli_mode=True,
        )
        agent = agent.model_copy(
            update={"mcp_config": {}, "security_analyzer": None})
        # 5) ä¸ç¤ºä¾‹ 22 ç›¸åŒï¼Œè®¾ç½®å›è°ƒä»¥æ”¶é›†äº‹ä»¶
        received_events: list = []
        last_event_time = {"ts": time.time()}

        def event_callback(event) -> None:
            event_type = type(event).__name__
            logger.info(f"ğŸ”” å›è°ƒæ”¶åˆ°äº‹ä»¶ï¼š{event_type}\n{event}")
            received_events.append(event)
            last_event_time["ts"] = time.time()

        # 6) åˆ›å»º RemoteConversation å¹¶æ‰§è¡Œç›¸åŒçš„ä¸¤æ­¥ä»»åŠ¡
        conversation = Conversation(
            agent=agent,
            host=server.base_url,
            callbacks=[event_callback],
            # visualize=True,
        )
        assert isinstance(conversation, RemoteConversation)
        # TODO é¿å…é˜»å¡çº¿ç¨‹
        conversation_id_str = str(conversation.state.id)
        try:
            logger.info(f"\nğŸ“‹ å¯¹è¯ IDï¼š{conversation.state.id}")
            logger.info("ğŸ“ æ­£åœ¨å‘é€æ¶ˆæ¯â€¦")
            conversation.send_message(message)
            logger.info("ğŸš€ æ­£åœ¨è¿è¡Œå¯¹è¯â€¦")
            conversation.run()
            logger.info("âœ… ä»»åŠ¡å®Œæˆï¼")
            logger.info(f"Agent çŠ¶æ€ï¼š{conversation.state.agent_status}")

            # ç­‰å¾…äº‹ä»¶ç¨³å®šï¼ˆ2 ç§’å†…æ— äº‹ä»¶ï¼‰
            logger.info("â³ æ­£åœ¨ç­‰å¾…äº‹ä»¶åœæ­¢â€¦")
            while time.time() - last_event_time["ts"] < 2.0:
                time.sleep(0.1)
            logger.info("âœ… äº‹ä»¶å·²åœæ­¢")

        finally:
            print("\nğŸ§¹ æ­£åœ¨æ¸…ç†å¯¹è¯â€¦")
            conversation.close()
    
    # ä¿å­˜å¯¹è¯IDåˆ°å·¥ä½œç›®å½•çš„æ˜ å°„
    try:
        # è¯»å–ç°æœ‰æ˜ å°„
        if os.path.exists(conversation_mapping_file):
            with open(conversation_mapping_file, 'r', encoding='utf-8') as f:
                mapping = json.load(f)
        else:
            mapping = {}
        
        # æ·»åŠ æ–°çš„æ˜ å°„
        mapping[conversation_id_str] = str(workspace_id)
        
        # ä¿å­˜æ˜ å°„
        with open(conversation_mapping_file, 'w', encoding='utf-8') as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å·²ä¿å­˜å¯¹è¯æ˜ å°„: {conversation_id_str} -> {workspace_id}")
    except Exception as e:
        logger.error(f"ä¿å­˜å¯¹è¯æ˜ å°„å¤±è´¥: {e}")
    
    return conversation_id_str


@app.get("/resumeConversation")
async def resume_conversation(conversation_id: str, message: str) -> str:
    """æ¢å¤ä¸€ä¸ªå·²æœ‰çš„å¯¹è¯"""
    # 1) ç¡®ä¿æˆ‘ä»¬æ‹¥æœ‰ LLM API Key
    api_key = os.getenv("LITELLM_API_KEY")
    assert api_key is not None, "æœªè®¾ç½® LITELLM_API_KEY ç¯å¢ƒå˜é‡ã€‚"

    llm = LLM(
        service_id="main-llm",
        model="openai/Qwen3-Next-80B-A3B-Instruct-FP8",
        base_url="https://oneapi.wchat.cc/v1",
        api_key=SecretStr(api_key),
    )
    
    # è·å–ä¼šè¯å¯¹åº”çš„å·¥ä½œç›®å½•
    base_dir = os.environ.get(
        "HOST_WORKSPACE_DIR",
        os.path.abspath(os.path.join(os.path.dirname(__file__), "..")),
    )
    host_workspace = os.path.abspath(base_dir)
    conversation_mapping_file = os.path.join(host_workspace, "conversation_mapping.json")
    
    try:
        # è¯»å–å¯¹è¯æ˜ å°„
        if os.path.exists(conversation_mapping_file):
            with open(conversation_mapping_file, 'r', encoding='utf-8') as f:
                mapping = json.load(f)
            
            if conversation_id in mapping:
                workspace_id = mapping[conversation_id]
                host_working_dir = os.path.join(host_workspace, "workspace", workspace_id)
                
                # æ£€æŸ¥å·¥ä½œç›®å½•æ˜¯å¦å­˜åœ¨
                if not os.path.exists(host_working_dir):
                    raise HTTPException(
                        status_code=404,
                        detail=f"å·¥ä½œç›®å½•ä¸å­˜åœ¨: {host_working_dir}"
                    )
                
                logger.info(f"æ‰¾åˆ°å¯¹è¯æ˜ å°„: {conversation_id} -> {workspace_id}")
            else:
                raise HTTPException(
                    status_code=404,
                    detail=f"æœªæ‰¾åˆ°å¯¹è¯IDçš„æ˜ å°„: {conversation_id}"
                )
        else:
            raise HTTPException(
                status_code=404,
                detail=f"å¯¹è¯æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {conversation_mapping_file}"
            )
    except json.JSONDecodeError:
        raise HTTPException(
            status_code=500,
            detail="å¯¹è¯æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯"
        )
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯æ˜ å°„å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–å¯¹è¯æ˜ å°„å¤±è´¥: {str(e)}"
        )
    
    # 2) ä¸ºæŒä¹…åŒ–åˆ›å»ºå®¿ä¸»æœºç›®å½•
    host_agent_workspace = os.path.join(host_workspace, ".conversations")
    os.makedirs(host_agent_workspace, exist_ok=True)

    # 3) ä½¿ç”¨ç›¸åŒçš„æŒä¹…åŒ–ç›®å½•å¯åŠ¨å®¹å™¨
    with PersistentDockerSandboxedAgentServer(
        base_image="ghcr.io/all-hands-ai/agent-server:4864c6f-custom-dev",
        mount_dir=host_working_dir,
        persistent_dirs={
            "/agent-server/workspace/conversations": host_agent_workspace,       # æŒä¹…åŒ–Agentå·¥ä½œåŒºæ•°æ®
        },
    ) as server:
        # 4) åˆ›å»º Agent
        agent = get_default_agent(
            llm=llm,
            working_dir="/workspace",
            cli_mode=True,
        )
        agent = agent.model_copy(
            update={"mcp_config": {}, "security_analyzer": None})

        # 5) è®¾ç½®å›è°ƒ
        received_events: list = []
        last_event_time = {"ts": time.time()}

        def event_callback(event) -> None:
            event_type = type(event).__name__
            logger.info(f"ğŸ”” å›è°ƒæ”¶åˆ°äº‹ä»¶ï¼š{event_type}\n{event}")
            received_events.append(event)
            last_event_time["ts"] = time.time()

        # 6) æ¢å¤è¿œç¨‹å¯¹è¯
        conversation = Conversation(
            agent=agent,
            host=server.base_url,
            callbacks=[event_callback],
            # visualize=True,
            conversation_id=conversation_id  # æŒ‡å®šè¦æ¢å¤çš„å¯¹è¯ID
        )
        assert isinstance(conversation, RemoteConversation)

        try:
            logger.info(f"\nğŸ“‹ æ¢å¤å¯¹è¯ IDï¼š{conversation.state.id}")
            logger.info("ğŸ“ æ­£åœ¨å‘é€æ¶ˆæ¯â€¦")
            conversation.send_message(message)
            logger.info("ğŸš€ æ­£åœ¨è¿è¡Œå¯¹è¯â€¦")
            conversation.run()
            logger.info("âœ… ä»»åŠ¡å®Œæˆï¼")
            logger.info(f"Agent çŠ¶æ€ï¼š{conversation.state.agent_status}")

            # ç­‰å¾…äº‹ä»¶ç¨³å®šï¼ˆ2 ç§’å†…æ— äº‹ä»¶ï¼‰
            logger.info("â³ æ­£åœ¨ç­‰å¾…äº‹ä»¶åœæ­¢â€¦")
            while time.time() - last_event_time["ts"] < 2.0:
                time.sleep(0.1)
            logger.info("âœ… äº‹ä»¶å·²åœæ­¢")

        finally:
            print("\nğŸ§¹ æ­£åœ¨æ¸…ç†å¯¹è¯â€¦")
            conversation.close()
    return conversation_id


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
