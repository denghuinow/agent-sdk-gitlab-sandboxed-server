import asyncio
import json
import os
import re
import subprocess
import threading
import time
import uuid
from dataclasses import dataclass
from pathlib import Path
from typing import Any
from urllib import error as urllib_error
from urllib import request as urllib_request
from urllib.parse import urlencode, urlparse, urlunparse

from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse, StreamingResponse
from openhands.sdk.conversation.conversation import Conversation
from pydantic import BaseModel, SecretStr

from openhands.sdk import LLM, get_logger
from openhands.sdk.conversation.impl.remote_conversation import RemoteConversation
from openhands.tools.preset.default import get_default_agent
from openhands.sdk.sandbox.docker import DockerSandboxedAgentServer, _run, build_agent_server_image


"""
Gitå·¥ä½œåŒºæ™ºèƒ½ä½“æœåŠ¡å™¨
------------------------------------
è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ªåŸºäº FastAPI çš„æœåŠ¡å™¨ï¼Œé›†æˆäº† OpenHands Agent Serverï¼Œå¹¶æä¾›äº†ä¸ Git ä»“åº“äº¤äº’çš„åŠŸèƒ½ã€‚ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

  1) æ„å»ºå¹¶å¯åŠ¨ OpenHands Agent Server çš„æ²™ç®±ç¯å¢ƒ
  2) åˆ›å»ºä¸€ä¸ª FastAPI åº”ç”¨æ¥å¤„ç† Git ä»“åº“æ“ä½œ
 3) ä¸æ²™ç®±åŒ–çš„æœåŠ¡å™¨äº¤äº’ä»¥æ‰§è¡Œ Git ä»»åŠ¡
  4) é€šè¿‡ç®€å•çš„ç›®å½•ç»“æ„ç®¡ç†ä¼šè¯æŒä¹…åŒ–
"""

logger = get_logger(__name__)

WORKSPACE_SUBDIR = "workspace"
MAPPING_FILE = "conversation_mapping.json"
_EVENT_FILE_PATTERN = re.compile(r"^event-(\d+)-([^.]+)\.json$")
FRONTEND_DIR = Path(__file__).with_name("frontend")
FRONTEND_INDEX = FRONTEND_DIR / "index.html"

SANDBOX_IDLE_TTL = float(os.environ.get("SANDBOX_IDLE_TTL", "1800"))
SANDBOX_CLEANUP_INTERVAL = float(os.environ.get("SANDBOX_CLEANUP_INTERVAL", "300"))


@dataclass
class SandboxEntry:
    sandbox: DockerSandboxedAgentServer
    workspace_dir: str
    last_access: float
    vscode_info: dict[str, Any] | None = None


_SANDBOX_REGISTRY: dict[str, SandboxEntry] = {}
_VSCODE_INFO: dict[str, dict[str, Any]] = {}
_REGISTRY_LOCK = threading.RLock()
_CLEANUP_TASK: asyncio.Task | None = None


class ConversationRequest(BaseModel):
    message: str
    git_repos: list[str] | None = None
    git_token: str | None = None
    workspace_id: str | None = None
    conversation_id: str | None = None


class ConversationResponse(BaseModel):
    conversation_id: str
    workspace_id: str


def _validate_workspace_id(workspace_id: str) -> str:
    """éªŒè¯å¹¶æ¸…ç†å·¥ä½œç©ºé—´ IDï¼Œç¡®ä¿ç›®å½•å‘½åè§„èŒƒã€‚"""
    if not workspace_id or not workspace_id.strip():
        raise HTTPException(status_code=400, detail="å·¥ä½œç©ºé—´ ID ä¸èƒ½ä¸ºç©º")

    # åªä¿ç•™å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿ï¼Œé¿å…è·¯å¾„éå†æ”»å‡»
    clean_id = re.sub(r'[^a-zA-Z0-9_]', '', workspace_id.strip())
    if not clean_id:
        raise HTTPException(status_code=400, detail="å·¥ä½œç©ºé—´ ID åŒ…å«æ— æ•ˆå­—ç¬¦")

    return clean_id


def _validate_conversation_id(conversation_id: str) -> str:
    """éªŒè¯ä¼šè¯ IDï¼Œé˜²æ­¢è·¯å¾„éå†ã€‚"""
    if not conversation_id or not conversation_id.strip():
        raise HTTPException(status_code=400, detail="ä¼šè¯ ID ä¸èƒ½ä¸ºç©º")

    clean_id = conversation_id.strip()
    if not re.fullmatch(r"[a-zA-Z0-9_-]+", clean_id):
        raise HTTPException(status_code=400, detail="ä¼šè¯ ID åŒ…å«æ— æ•ˆå­—ç¬¦")

    return clean_id


def _get_workspace_root() -> str:
    """è·å–å·¥ä½œç©ºé—´æ ¹ç›®å½•ï¼Œç¡®ä¿ç›®å½•å­˜åœ¨ã€‚"""
    base_dir = os.environ.get("HOST_WORKSPACE_DIR", os.path.dirname(__file__))
    workspace_root = os.path.join(base_dir, WORKSPACE_SUBDIR)
    os.makedirs(workspace_root, exist_ok=True)
    return workspace_root


def _safe_load_mapping(mapping_file: str) -> dict:
    """å®‰å…¨åŠ è½½ä¼šè¯æ˜ å°„æ–‡ä»¶ã€‚"""
    if not os.path.exists(mapping_file):
        return {}
    
    try:
        with open(mapping_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            # éªŒè¯æ•°æ®æ ¼å¼
            if not isinstance(data, dict):
                raise ValueError("æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šåº”ä¸ºå­—å…¸ç±»å‹")
            return data
    except (json.JSONDecodeError, ValueError) as e:
        logger.error("æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯: %s", e)
        raise HTTPException(status_code=500, detail="æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯") from e
    except OSError as e:
        logger.error("è¯»å–æ˜ å°„æ–‡ä»¶å¤±è´¥: %s", e)
        raise HTTPException(status_code=500, detail="è¯»å–æ˜ å°„å¤±è´¥") from e


def _safe_save_mapping(mapping_file: str, mapping: dict) -> None:
    """å®‰å…¨ä¿å­˜ä¼šè¯æ˜ å°„æ–‡ä»¶ã€‚"""
    try:
        with open(mapping_file, "w", encoding="utf-8") as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2)
    except OSError as e:
        logger.error("ä¿å­˜æ˜ å°„æ–‡ä»¶å¤±è´¥: %s", e)
        raise HTTPException(status_code=500, detail="ä¿å­˜æ˜ å°„å¤±è´¥") from e


def _event_file_sort_key(path: Path) -> tuple[int, str]:
    match = _EVENT_FILE_PATTERN.match(path.name)
    if match:
        return int(match.group(1)), match.group(2)
    return 10**12, path.name


def _load_events_from_directory(events_dir: Path) -> list[dict]:
    event_files = sorted(events_dir.glob("event-*-*.json"), key=_event_file_sort_key)
    events: list[dict] = []
    for event_file in event_files:
        try:
            with event_file.open("r", encoding="utf-8") as f:
                events.append(json.load(f))
        except json.JSONDecodeError as exc:
            logger.error("äº‹ä»¶æ–‡ä»¶æ ¼å¼é”™è¯¯: %s", event_file)
            raise HTTPException(status_code=500, detail=f"äº‹ä»¶æ–‡ä»¶æ ¼å¼é”™è¯¯: {event_file.name}") from exc
        except OSError as exc:
            logger.error("è¯»å–äº‹ä»¶æ–‡ä»¶å¤±è´¥: %s", event_file)
            raise HTTPException(status_code=500, detail="è¯»å–äº‹ä»¶æ–‡ä»¶å¤±è´¥") from exc
    return events


def _clone_repos_safe(project_dir: str, git_repos: list[str], git_token: str = None) -> None:
    """å®‰å…¨åœ°å…‹éš† Git ä»“åº“åˆ°é¡¹ç›®ç›®å½•ã€‚"""
    if not git_repos:
        return

    token = git_token.strip() if git_token else ""
    
    for repo_url in git_repos:
        repo_url = repo_url.strip()
        if not repo_url:
            continue

        # æå–ä»“åº“åï¼Œé˜²æ­¢è·¯å¾„æ³¨å…¥
        repo_name = os.path.basename(repo_url.rstrip('/')).replace('.git', '')
        if not repo_name:
            continue
            
        # éªŒè¯ä»“åº“åçš„å®‰å…¨æ€§
        import re
        if not re.match(r'^[a-zA-Z0-9_-]+$', repo_name):
            logger.warning("è·³è¿‡ä¸å®‰å…¨çš„ä»“åº“å: %s", repo_name)
            continue

        dest_path = os.path.join(project_dir, repo_name)
        if os.path.exists(dest_path):
            logger.info("ä»“åº“å·²å­˜åœ¨ï¼Œè·³è¿‡: %s", repo_url)
            continue

        # å¤„ç†è®¤è¯
        clone_url = repo_url
        if token and token.lower() != "none":
            parsed = urlparse(repo_url)
            if parsed.scheme in {"http", "https"} and not parsed.username:
                clone_url = urlunparse(parsed._replace(
                    netloc=f"oauth2:{token}@{parsed.netloc}"
                ))

        try:
            result = subprocess.run([
                "git", "clone", "--depth", "1", clone_url, dest_path
            ], check=True, capture_output=True, text=True, timeout=300)
            logger.info("æˆåŠŸå…‹éš†ä»“åº“: %s", repo_url)
        except subprocess.TimeoutExpired:
            raise HTTPException(status_code=408, detail=f"å…‹éš†è¶…æ—¶: {repo_url}")
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr
            if token:
                error_msg = error_msg.replace(token, "***")
            raise HTTPException(
                status_code=400, 
                detail=f"å…‹éš†å¤±è´¥: {repo_url}\n{error_msg}"
            ) from e


def _create_sandbox_with_persistence(mount_dir: str):
    """åˆ›å»ºå¸¦æœ‰æŒä¹…åŒ–æŒ‚è½½çš„æ²™ç®±æœåŠ¡å™¨ã€‚"""
    class PersistentSandbox(DockerSandboxedAgentServer):
        def __init__(self, mount_dir: str):
            super().__init__(
                base_image="ghcr.io/all-hands-ai/agent-server:latest-python",
                mount_dir=mount_dir,
                host_port=0,  # è‡ªåŠ¨åˆ†é…ç«¯å£
            )
            self._mount_dir = mount_dir

        def __enter__(self):
            # éªŒè¯ Docker
            if _run(["docker", "version"]).returncode != 0:
                raise RuntimeError("Docker æœªè¿è¡Œï¼Œè¯·å¯åŠ¨ Docker æœåŠ¡")

            # æ„å»ºé•œåƒï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self._image and "ghcr.io/all-hands-ai/agent-server" not in self._image:
                self._image = build_agent_server_image(
                    base_image=self._image,
                    target=self._target,
                    platforms=self._platform,
                )

            # å‡†å¤‡ Docker è¿è¡Œå‚æ•°
            flags = ["-v", f"{self._mount_dir}:/workspace"]
            
            # æ·»åŠ ç¯å¢ƒå˜é‡
            for key in self._forward_env:
                if key in os.environ:
                    flags.extend(["-e", f"{key}={os.environ[key]}"])

            # è¿è¡Œå®¹å™¨
            run_cmd = [
                "docker", "run", "--user", "0:0", "-d", "--platform", self._platform,
                "--rm", "--name", f"agent-server-{int(time.time())}-{uuid.uuid4().hex[:8]}",
                "-p", f"{self.host_port}:8000", *flags, self._image,
                "--host", "0.0.0.0", "--port", "8000"
            ]
            
            proc = _run(run_cmd)
            if proc.returncode != 0:
                raise RuntimeError(f"å¯åŠ¨å®¹å™¨å¤±è´¥: {proc.stderr}")

            self.container_id = proc.stdout.strip()
            logger.info("å¯åŠ¨å®¹å™¨: %s", self.container_id)

            # å¯åŠ¨æ—¥å¿—çº¿ç¨‹
            if self.detach_logs:
                from threading import Thread
                self._logs_thread = Thread(target=self._stream_docker_logs, daemon=True)
                self._logs_thread.start()

            self._wait_for_health()
            logger.info("API æœåŠ¡å™¨å°±ç»ª: %s", self.base_url)
            return self

    return PersistentSandbox(mount_dir)


def _get_sandbox_entry(workspace_id: str) -> SandboxEntry | None:
    with _REGISTRY_LOCK:
        return _SANDBOX_REGISTRY.get(workspace_id)


def _touch_workspace(workspace_id: str) -> float | None:
    now = time.time()
    with _REGISTRY_LOCK:
        entry = _SANDBOX_REGISTRY.get(workspace_id)
        if entry:
            entry.last_access = now
            return now
    return None


def _set_vscode_info(workspace_id: str, info: dict[str, Any] | None) -> None:
    with _REGISTRY_LOCK:
        if info is None:
            _VSCODE_INFO.pop(workspace_id, None)
            entry = _SANDBOX_REGISTRY.get(workspace_id)
            if entry:
                entry.vscode_info = None
            return
        _VSCODE_INFO[workspace_id] = info
        entry = _SANDBOX_REGISTRY.get(workspace_id)
        if entry:
            entry.vscode_info = info


def _get_vscode_info(workspace_id: str) -> dict[str, Any] | None:
    with _REGISTRY_LOCK:
        entry = _SANDBOX_REGISTRY.get(workspace_id)
        if entry and entry.vscode_info:
            return entry.vscode_info
        return _VSCODE_INFO.get(workspace_id)


def _ensure_sandbox_entry(
    workspace_id: str, workspace_dir: str
) -> tuple[SandboxEntry, bool]:
    existing = _get_sandbox_entry(workspace_id)
    if existing:
        existing.last_access = time.time()
        return existing, False

    sandbox = _create_sandbox_with_persistence(workspace_dir)
    server = sandbox.__enter__()
    entry = SandboxEntry(
        sandbox=server,
        workspace_dir=workspace_dir,
        last_access=time.time(),
        vscode_info=_get_vscode_info(workspace_id),
    )

    with _REGISTRY_LOCK:
        other = _SANDBOX_REGISTRY.get(workspace_id)
        if other:
            entry_to_use = other
        else:
            _SANDBOX_REGISTRY[workspace_id] = entry
            entry_to_use = entry

    if entry_to_use is not entry:
        try:
            sandbox.__exit__(None, None, None)
        except Exception:  # noqa: BLE001
            logger.exception("é‡å¤åˆ›å»ºæ²™ç®±æ—¶æ¸…ç†å¤±è´¥: %s", workspace_id)
        entry_to_use.last_access = time.time()
        return entry_to_use, False

    return entry, True


def _dispose_workspace(workspace_id: str) -> bool:
    with _REGISTRY_LOCK:
        entry = _SANDBOX_REGISTRY.pop(workspace_id, None)
        _VSCODE_INFO.pop(workspace_id, None)
    if not entry:
        return False
    try:
        entry.sandbox.__exit__(None, None, None)
    except Exception:  # noqa: BLE001
        logger.exception("é‡Šæ”¾æ²™ç®±å¤±è´¥: %s", workspace_id)
    return True


def _collect_expired_workspaces(now: float | None = None) -> list[str]:
    now = now or time.time()
    with _REGISTRY_LOCK:
        return [
            workspace_id
            for workspace_id, entry in _SANDBOX_REGISTRY.items()
            if now - entry.last_access > SANDBOX_IDLE_TTL
        ]


def _cleanup_expired_entries(now: float | None = None) -> list[str]:
    expired = _collect_expired_workspaces(now)
    for workspace_id in expired:
        _dispose_workspace(workspace_id)
    return expired


def _cleanup_all_workspaces() -> None:
    for workspace_id in list(_SANDBOX_REGISTRY.keys()):
        _dispose_workspace(workspace_id)


def _build_vscode_payload(
    workspace_id: str,
    entry: SandboxEntry,
    info: dict[str, Any] | None,
    source: str,
) -> dict[str, Any]:
    now = time.time()
    expires_at = entry.last_access + SANDBOX_IDLE_TTL
    remaining = max(0.0, expires_at - now)
    payload: dict[str, Any] = {
        "workspace_id": workspace_id,
        "ttl_seconds": SANDBOX_IDLE_TTL,
        "last_active": entry.last_access,
        "expires_at": expires_at,
        "remaining_seconds": remaining,
        "source": source,
    }
    if info and info.get("url"):
        payload["url"] = info["url"]
    return payload


def _fetch_vscode_info(entry: SandboxEntry) -> dict[str, Any] | None:
    base_url = entry.sandbox.base_url.rstrip("/")
    query = urlencode({"base_url": base_url})
    request_url = f"{base_url}/api/vscode/url?{query}"
    try:
        with urllib_request.urlopen(request_url, timeout=10) as response:
            if response.status != 200:
                raise RuntimeError(
                    f"è¯·æ±‚ VSCode URL å¤±è´¥ï¼ŒçŠ¶æ€ç  {response.status}"
                )
            data = json.loads(response.read().decode("utf-8"))
    except (urllib_error.URLError, RuntimeError, json.JSONDecodeError) as exc:
        logger.warning("è·å– VSCode URL å¤±è´¥: %s", exc)
        return None

    url = data.get("url")
    if not url:
        return None

    return {
        "url": url,
        "fetched_at": time.time(),
        "base_url": base_url,
    }


def _ensure_vscode_info_for_entry(
    workspace_id: str, entry: SandboxEntry
) -> tuple[dict[str, Any] | None, str]:
    cached = _get_vscode_info(workspace_id)
    if cached:
        return cached, "cache"

    fetched = _fetch_vscode_info(entry)
    if fetched:
        _set_vscode_info(workspace_id, fetched)
        return fetched, "fetch"
    return cached, "unavailable"


async def _cleanup_loop() -> None:
    try:
        while True:
            await asyncio.sleep(max(1.0, SANDBOX_CLEANUP_INTERVAL))
            expired = await asyncio.to_thread(_cleanup_expired_entries)
            if expired:
                logger.info("å·²æ¸…ç†ç©ºé—²å·¥ä½œç©ºé—´: %s", ", ".join(expired))
    except asyncio.CancelledError:  # noqa: PERF203
        logger.info("åå°æ¸…ç†ä»»åŠ¡å·²å–æ¶ˆ")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="Git Integration Server",
    description="A server for handling Git repository operations with OpenHands agents (with persistence)",
    version="0.1.0"
)


@app.on_event("startup")
async def _startup_cleanup_task() -> None:
    global _CLEANUP_TASK
    if _CLEANUP_TASK is None:
        _CLEANUP_TASK = asyncio.create_task(_cleanup_loop())


@app.on_event("shutdown")
async def _shutdown_cleanup_task() -> None:
    global _CLEANUP_TASK
    if _CLEANUP_TASK is not None:
        _CLEANUP_TASK.cancel()
        try:
            await _CLEANUP_TASK
        except asyncio.CancelledError:  # noqa: PERF203
            pass
        _CLEANUP_TASK = None
    await asyncio.to_thread(_cleanup_all_workspaces)


@app.get("/")
def serve_frontend() -> FileResponse:
    """æä¾›æœ€ç®€å•çš„å‰ç«¯é¡µé¢ï¼Œä¾¿äºç›´æ¥è®¿é—®æœåŠ¡ã€‚"""
    if not FRONTEND_INDEX.exists():
        raise HTTPException(status_code=503, detail="å‰ç«¯ç•Œé¢å°šæœªéƒ¨ç½²")
    return FileResponse(FRONTEND_INDEX)


def _format_sse(event: str, data: dict) -> str:
    payload = json.dumps(data, ensure_ascii=False)
    return f"event: {event}\ndata: {payload}\n\n"


@app.post("/conversation")
async def handle_conversation(request: ConversationRequest) -> StreamingResponse:
    """åˆ›å»ºæˆ–æ¢å¤å¯¹è¯ï¼Œå¹¶é€šè¿‡ SSE æ¨é€äº‹ä»¶ã€‚"""

    api_key = os.getenv("LITELLM_API_KEY")
    assert api_key is not None, "æœªè®¾ç½® LITELLM_API_KEY ç¯å¢ƒå˜é‡ã€‚"

    llm = LLM(
        service_id="main-llm",
        model="openai/qwen3-next-80b-a3b-instruct",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        api_key=SecretStr(api_key),
    )

    workspace_root = _get_workspace_root()
    conversation_mapping_file = os.path.join(
        workspace_root, MAPPING_FILE
    )
    conversation_mapping = _safe_load_mapping(conversation_mapping_file)

    is_resume = bool(request.conversation_id)
    workspace_id = request.workspace_id
    if workspace_id:
        workspace_id = _validate_workspace_id(workspace_id)
    conversation_id = request.conversation_id

    if is_resume:
        if conversation_id not in conversation_mapping:
            raise HTTPException(
                status_code=404,
                detail=f"æœªæ‰¾åˆ°å¯¹è¯IDçš„æ˜ å°„: {conversation_id}",
            )
        mapped_workspace_id = _validate_workspace_id(conversation_mapping[conversation_id])
        if workspace_id and workspace_id != mapped_workspace_id:
            raise HTTPException(
                status_code=400,
                detail=(
                    "ä¼ å…¥çš„ workspace_id ä¸ä¼šè¯æ˜ å°„ä¸ä¸€è‡´: "
                    f"{workspace_id} â‰  {mapped_workspace_id}"
                ),
            )
        workspace_id = mapped_workspace_id
    else:
        if workspace_id:
            logger.info("ä½¿ç”¨å·²æœ‰å·¥ä½œç©ºé—´: %s", workspace_id)
        else:
            workspace_id = uuid.uuid4().hex
            logger.info("åˆ›å»ºæ–°çš„å·¥ä½œç©ºé—´: %s", workspace_id)

    workspace_dir = os.path.join(workspace_root, workspace_id)
    if is_resume:
        if not os.path.exists(workspace_dir):
            raise HTTPException(
                status_code=404,
                detail=f"å·¥ä½œç›®å½•ä¸å­˜åœ¨: {workspace_dir}",
            )
    else:
        if request.workspace_id:
            if not os.path.exists(workspace_dir):
                raise HTTPException(
                    status_code=404,
                    detail=f"å·¥ä½œç›®å½•ä¸å­˜åœ¨: {workspace_dir}",
                )
        else:
            os.makedirs(workspace_dir, exist_ok=True)
    project_dir = os.path.join(workspace_dir, "project")
    os.makedirs(project_dir, exist_ok=True)
    if not is_resume:
        _clone_repos_safe(project_dir, request.git_repos or [], request.git_token)

    async def event_stream():
        loop = asyncio.get_running_loop()
        queue: asyncio.Queue[str | None] = asyncio.Queue()
        conversation_id_holder: dict[str | None] = {"id": None}

        def push_event(event_name: str, data: dict) -> None:
            loop.call_soon_threadsafe(queue.put_nowait, _format_sse(event_name, data))

        def finish_stream() -> None:
            loop.call_soon_threadsafe(queue.put_nowait, None)

        def worker() -> None:
            nonlocal conversation_mapping
            conversation: RemoteConversation | None = None
            try:
                entry, _ = _ensure_sandbox_entry(workspace_id, workspace_dir)
                server = entry.sandbox
                _touch_workspace(workspace_id)

                info, source = _ensure_vscode_info_for_entry(workspace_id, entry)
                if info:
                    push_event(
                        "vscode-info",
                        _build_vscode_payload(workspace_id, entry, info, source),
                    )

                agent = get_default_agent(
                    llm=llm,
                    working_dir="/workspace/project",
                    cli_mode=True,
                )
                agent = agent.model_copy(
                    update={
                        "mcp_config": {},
                        "security_analyzer": None,
                        "condenser": None,
                    }
                )

                last_event_time = {"ts": time.time()}

                def event_callback(event) -> None:
                    event_type = type(event).__name__
                    logger.info("ğŸ”” å›è°ƒæ”¶åˆ°äº‹ä»¶ï¼š%s\n%s", event_type, event)
                    last_event_time["ts"] = time.time()
                    payload = event.model_dump(mode="json")  # type: ignore[arg-type]
                    payload["event_type"] = event_type
                    payload["conversation_id"] = conversation_id_holder["id"]
                    payload["workspace_id"] = workspace_id
                    push_event("agent-event", payload)

                conversation_kwargs = dict(
                    agent=agent,
                    host=server.base_url,
                    callbacks=[event_callback],
                    visualize=True,
                )
                if is_resume and conversation_id:
                    conversation_kwargs["conversation_id"] = conversation_id

                conversation = Conversation(**conversation_kwargs)
                assert isinstance(conversation, RemoteConversation)
                conversation_id_str = str(conversation.state.id)
                conversation_id_holder["id"] = conversation_id_str
                push_event(
                    "conversation-ready",
                    {
                        "conversation_id": conversation_id_str,
                        "workspace_id": workspace_id,
                        "is_resume": is_resume,
                    },
                )

                logger.info("\nğŸ“‹ å¯¹è¯ IDï¼š%s", conversation.state.id)
                logger.info("ğŸ“ æ­£åœ¨å‘é€æ¶ˆæ¯â€¦")
                conversation.send_message(request.message)
                push_event(
                    "message-queued",
                    {
                        "conversation_id": conversation_id_str,
                        "workspace_id": workspace_id,
                        "message": request.message,
                    },
                )

                logger.info("ğŸš€ æ­£åœ¨è¿è¡Œå¯¹è¯â€¦")
                conversation.run()
                logger.info("âœ… ä»»åŠ¡å®Œæˆï¼")
                logger.info("Agent çŠ¶æ€ï¼š%s", conversation.state.agent_status)
                push_event(
                    "conversation-finished",
                    {
                        "conversation_id": conversation_id_str,
                        "workspace_id": workspace_id,
                        "agent_status": conversation.state.agent_status,
                    },
                )

                logger.info("â³ æ­£åœ¨ç­‰å¾…äº‹ä»¶åœæ­¢â€¦")
                while time.time() - last_event_time["ts"] < 2.0:
                    time.sleep(0.1)
                logger.info("âœ… äº‹ä»¶å·²åœæ­¢")

                if not is_resume and conversation_id_str:
                    conversation_mapping[conversation_id_str] = workspace_id
                    _safe_save_mapping(conversation_mapping_file, conversation_mapping)

            except Exception as exc:  # noqa: BLE001
                logger.exception("ä¼šè¯å¤„ç†å¤±è´¥")
                push_event(
                    "error",
                    {
                        "message": str(exc),
                        "workspace_id": workspace_id,
                        "conversation_id": conversation_id_holder["id"],
                    },
                )
            finally:
                if conversation is not None:
                    try:
                        conversation.close()
                    except Exception:  # noqa: BLE001
                        logger.exception("å…³é—­ä¼šè¯å¤±è´¥")
                _touch_workspace(workspace_id)
                push_event(
                    "cleanup-complete",
                    {
                        "conversation_id": conversation_id_holder["id"],
                        "workspace_id": workspace_id,
                    },
                )
                finish_stream()

        worker_task = asyncio.create_task(asyncio.to_thread(worker))

        try:
            while True:
                chunk = await queue.get()
                if chunk is None:
                    break
                yield chunk
        finally:
            await worker_task

    return StreamingResponse(event_stream(), media_type="text/event-stream")


@app.get("/workspace/{workspace_id}/conversations/{conversation_id}/events")
async def get_conversation_events(workspace_id: str, conversation_id: str) -> dict:
    """è·å–æŒ‡å®šä¼šè¯çš„æ‰€æœ‰äº‹ä»¶ã€‚"""

    normalized_workspace_id = _validate_workspace_id(workspace_id)
    normalized_conversation_id = _validate_conversation_id(conversation_id)

    workspace_root = Path(_get_workspace_root())
    workspace_dir = workspace_root / normalized_workspace_id
    if not workspace_dir.exists() or not workspace_dir.is_dir():
        raise HTTPException(status_code=404, detail="å·¥ä½œç©ºé—´ä¸å­˜åœ¨")

    conversation_dir = workspace_dir / "conversations" / normalized_conversation_id
    if not conversation_dir.exists() or not conversation_dir.is_dir():
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    events_dir = conversation_dir / "event_service" / "events"
    if not events_dir.exists() or not events_dir.is_dir():
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°äº‹ä»¶ç›®å½•")

    events = _load_events_from_directory(events_dir)

    return {
        "workspace_id": normalized_workspace_id,
        "conversation_id": normalized_conversation_id,
        "event_count": len(events),
        "events": events,
    }


@app.get("/workspace/{workspace_id}/conversations/{conversation_id}/state")
async def get_conversation_state(workspace_id: str, conversation_id: str) -> dict:
    """è·å–æŒ‡å®šä¼šè¯çš„åŸºç¡€çŠ¶æ€ã€‚"""

    normalized_workspace_id = _validate_workspace_id(workspace_id)
    normalized_conversation_id = _validate_conversation_id(conversation_id)

    workspace_root = Path(_get_workspace_root())
    workspace_dir = workspace_root / normalized_workspace_id
    if not workspace_dir.exists() or not workspace_dir.is_dir():
        raise HTTPException(status_code=404, detail="å·¥ä½œç©ºé—´ä¸å­˜åœ¨")

    conversation_dir = workspace_dir / "conversations" / normalized_conversation_id
    if not conversation_dir.exists() or not conversation_dir.is_dir():
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    state_file = conversation_dir / "event_service" / "base_state.json"
    if not state_file.exists() or not state_file.is_file():
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°çŠ¶æ€æ–‡ä»¶")

    try:
        with state_file.open("r", encoding="utf-8") as f:
            state_data = json.load(f)
    except json.JSONDecodeError as exc:
        logger.error("çŠ¶æ€æ–‡ä»¶æ ¼å¼é”™è¯¯: %s", state_file)
        raise HTTPException(status_code=500, detail="çŠ¶æ€æ–‡ä»¶æ ¼å¼é”™è¯¯") from exc
    except OSError as exc:
        logger.error("è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: %s", state_file)
        raise HTTPException(status_code=500, detail="è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥") from exc

    return {
        "workspace_id": normalized_workspace_id,
        "conversation_id": normalized_conversation_id,
        "state": state_data,
    }


@app.get("/workspace/{workspace_id}/project/file")
async def download_project_file(workspace_id: str, file_path: str) -> FileResponse:
    """ä¸‹è½½æŒ‡å®šå·¥ä½œç©ºé—´ project ç›®å½•ä¸­çš„æ–‡ä»¶ã€‚"""

    normalized_workspace_id = _validate_workspace_id(workspace_id)
    relative_path = file_path.strip()
    if not relative_path:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")

    workspace_root = Path(_get_workspace_root())
    workspace_dir = workspace_root / normalized_workspace_id
    project_dir = workspace_dir / "project"

    if not workspace_dir.exists():
        raise HTTPException(status_code=404, detail="å·¥ä½œç©ºé—´ä¸å­˜åœ¨")
    if not project_dir.exists():
        raise HTTPException(status_code=404, detail="project ç›®å½•ä¸å­˜åœ¨")

    try:
        project_dir_resolved = project_dir.resolve(strict=True)
    except FileNotFoundError as exc:
        raise HTTPException(status_code=404, detail="project ç›®å½•ä¸å­˜åœ¨") from exc

    requested_path = (project_dir / relative_path).resolve(strict=False)
    try:
        requested_path.relative_to(project_dir_resolved)
    except ValueError as exc:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶è·¯å¾„è¶Šç•Œ") from exc

    if not requested_path.exists() or not requested_path.is_file():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    return FileResponse(path=requested_path, filename=requested_path.name)


@app.get("/workspace/{workspace_id}/vscode")
async def get_workspace_vscode(workspace_id: str) -> dict[str, Any]:
    normalized_workspace_id = _validate_workspace_id(workspace_id)
    entry = _get_sandbox_entry(normalized_workspace_id)
    if not entry:
        raise HTTPException(status_code=404, detail="å½“å‰å·¥ä½œç©ºé—´å°šæœªå¯åŠ¨æ²™ç®±")

    info, source = _ensure_vscode_info_for_entry(normalized_workspace_id, entry)
    if not info:
        raise HTTPException(status_code=503, detail="VSCode æš‚ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")

    _touch_workspace(normalized_workspace_id)
    return _build_vscode_payload(normalized_workspace_id, entry, info, source)


@app.delete("/workspace/{workspace_id}/vscode")
async def delete_workspace_vscode(workspace_id: str) -> dict[str, Any]:
    normalized_workspace_id = _validate_workspace_id(workspace_id)
    disposed = await asyncio.to_thread(_dispose_workspace, normalized_workspace_id)
    if not disposed:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°éœ€è¦åœæ­¢çš„æ²™ç®±å®ä¾‹")
    return {
        "workspace_id": normalized_workspace_id,
        "status": "stopped",
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
